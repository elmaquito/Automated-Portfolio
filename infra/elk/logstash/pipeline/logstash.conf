input {
  kafka {
    bootstrap_servers => "kafka:29092"
    topics => ["metrics"]
    codec => "json"
    group_id => "logstash-consumer"
    consumer_threads => 3
  }
}

filter {
  # Parse timestamp
  date {
    match => ["timestamp", "ISO8601"]
    target => "@timestamp"
  }
  
  # Add computed fields
  mutate {
    add_field => {
      "metric_type" => "timeseries"
    }
  }
  
  # Tag anomalies
  if [is_anomaly] == 1 {
    mutate {
      add_tag => ["anomaly"]
    }
  }
  
  # Convert numeric fields
  mutate {
    convert => {
      "series_id" => "integer"
      "latency_ms" => "float"
      "error_rate_pct" => "float"
      "throughput_rps" => "float"
      "is_anomaly" => "integer"
    }
  }
}

output {
  elasticsearch {
    hosts => ["http://elasticsearch:9200"]
    index => "metrics-%{+YYYY.MM.dd}"
    document_id => "%{series_id}-%{+YYYY.MM.dd.HH.mm.ss}"
  }
  
  # Debug output (optional)
  # stdout {
  #   codec => rubydebug
  # }
}
