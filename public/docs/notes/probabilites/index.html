<!DOCTYPE html>
<html lang="fr">
<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Bases IA : Probabilites | Ismael Martinez - Portfolio &amp; Documentation</title>
    <meta name="description" content="Note de cours concernant les Probabilites appliqués à l&#39;IA.">
    
    
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet">
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
    
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
        }
        .navbar-brand {
            font-weight: bold;
            font-size: 1.5rem;
        }
        .hero-section {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 4rem 0;
        }
        .content-section {
            padding: 3rem 0;
        }
        .card {
            transition: transform 0.2s;
        }
        .card:hover {
            transform: translateY(-5px);
        }
        footer {
            background: #2d3748;
            color: white;
            padding: 2rem 0;
            margin-top: 3rem;
        }
        .highlight {
            background: #f8f9fa;
            border-left: 4px solid #007bff;
            padding: 1rem;
            margin: 1rem 0;
        }
    </style>
</head>
<body>
    
    <nav class="navbar navbar-expand-lg navbar-light bg-light shadow-sm">
        <div class="container">
            <a class="navbar-brand" href="http://localhost:1313/">
                <i class="fas fa-code"></i> Ismael Martinez - Portfolio &amp; Documentation
            </a>
            <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNav">
                <span class="navbar-toggler-icon"></span>
            </button>
            <div class="collapse navbar-collapse" id="navbarNav">
                <ul class="navbar-nav ms-auto">
                    
                    <li class="nav-item">
                        <a class="nav-link" href="/">Accueil</a>
                    </li>
                    
                    <li class="nav-item">
                        <a class="nav-link" href="/about/">À propos</a>
                    </li>
                    
                    <li class="nav-item">
                        <a class="nav-link" href="/projects/">Projets</a>
                    </li>
                    
                    <li class="nav-item">
                        <a class="nav-link" href="/docs/">Documentation</a>
                    </li>
                    
                    <li class="nav-item">
                        <a class="nav-link" href="/blog/">Blog</a>
                    </li>
                    
                    <li class="nav-item">
                        <a class="nav-link" href="/contact/">Contact</a>
                    </li>
                    
                </ul>
            </div>
        </div>
    </nav>

    
    <main>
        
<div class="hero-section text-center">
    <div class="container">
        <h1 class="display-4 mb-4">Bases IA : Probabilites</h1>
        <p class="lead">Note de cours concernant les Probabilites appliqués à l&#39;IA.</p>
    </div>
</div>

<div class="content-section">
    <div class="container">
        <div class="row">
            <div class="col-lg-8 mx-auto">
                <article>
                    <p>L&rsquo;univers et les evènements :</p>
<ul>
<li>Univers : ensemble des éléments d&rsquo;étude</li>
<li>Espace échantillonal : ensemble de tous les résultats possibles d&rsquo;une expérience aléatoire</li>
<li>Evénement : sous-ensemble de l&rsquo;espace échantillonal</li>
<li>Evenement élémentaire : événement ne contenant qu&rsquo;un seul résultat</li>
<li>Evenement certain : événement qui se produit toujours</li>
<li>Evenement impossible : événement qui ne se produit jamais</li>
<li>Evenement contraire : complémentaire d&rsquo;un événement</li>
<li>Evenement incompatible : événements qui ne peuvent pas se produire simultanément</li>
<li>Evenement complémentaire : la réalisation d&rsquo;un événement n&rsquo;affecte pas la probabilité d&rsquo;un autre</li>
</ul>
<h4 id="opérations-sur-les-évènements-">Opérations sur les évènements :</h4>
<ul>
<li>Union (A ∪ B) : événement qui se produit si A ou B se produit
<ul>
<li>Ex:emple : lancer un dé, A = obtenir un nombre pair {2,4,6}, B = obtenir un nombre supérieur à 4 {5,6}, A ∪ B = {2,4,5,6}</li>
</ul>
</li>
<li>Intersection (A ∩ B) : événement qui se produit si A et B se produisent simultanément
<ul>
<li>Exemple : lancer un dé, A = obtenir un nombre pair {2,4,6}, B = obtenir un nombre supérieur à 4 {5,6}, A ∩ B = {6}</li>
</ul>
</li>
<li>Différence (A \ B) : événement qui se produit si A se produit mais pas B
<ul>
<li>Exemple : lancer un dé, A = obtenir un nombre pair {2,4,6}, B = obtenir un nombre supérieur à 4 {5,6}, A \ B = {2,4}</li>
</ul>
</li>
<li>Complémentaire (A&rsquo;) : événement qui se produit si A ne se produit pas
<ul>
<li>Exemple : lancer un dé, A = obtenir un nombre pair {2,4,6}, A&rsquo; = {1,3,5}</li>
</ul>
</li>
<li>Loi des grands nombres : avec un grand nombre d&rsquo;essais, la fréquence relative d&rsquo;un événement converge vers sa probabilité théorique</li>
<li>Indépendance : deux événements A et B sont indépendants si la réalisation de l&rsquo;un n&rsquo;affecte pas la probabilité de l&rsquo;autre (P(A ∩ B) = P(A) * P(B))</li>
</ul>
<h3 id="axiome-des-probabilités-">Axiome des probabilités :</h3>
<ul>
<li>Non-négativité : P(A) ≥ 0 pour tout événement A</li>
<li>Normalisation : P(Ω) = 1, où Ω est l&rsquo;univers</li>
<li>Additivité : pour des événements mutuellement exclusifs A1, A2, &hellip;, An, P(A1 ∪ A2 ∪ &hellip; ∪ An) = P(A1) + P(A2) + &hellip; + P(An)</li>
</ul>
<h4 id="probabilités-dun-évènement">Probabilités d&rsquo;un évènement</h4>
<ul>
<li>Probabilité d&rsquo;un événement A : P(A) = nombre de cas favorables / nombre de cas possibles
<ul>
<li>Exemple : lancer un dé, A = obtenir un nombre pair {2,4,6}, P(A) = 3/6 = 0.5</li>
<li>Espace échantillonal : {1,2,3,4,5,6}</li>
<li>Cas favorables : {2,4,6}</li>
<li>Cas possibles : {1,2,3,4,5,6}</li>
<li>P(A) = 3/6 = 0.5</li>
<li></li>
</ul>
</li>
</ul>
<h4 id="probabilités-conditionnelle">Probabilités conditionnelle</h4>
<ul>
<li>Probabilité conditionnelle (P(A|B)) : probabilité de A sachant que B s&rsquo;est produit
<ul>
<li>Exemple : lancer deux dés, A = obtenir un total de 7, B = obtenir un 4 sur le premier dé, P(A|B) = 1/6</li>
<li>Formule de Bayes : P(A|B) = (P(B|A) * P(A)) / P(B)</li>
<li>Exemple : maladie et test médical, P(M|T) = (P(T|M) * P(M)) / P(T)</li>
</ul>
</li>
</ul>
<h4 id="indépendance-des-évènements">Indépendance des évènements</h4>
<ul>
<li>Deux événements A et B sont indépendants si P(A ∩ B) = P(A) * P(B)
<ul>
<li>Exemple : lancer deux pièces, A = obtenir face sur la première, B = obtenir face sur la deuxième, P(A ∩ B) = 1/4 = P(A) * P(B) = 1/2 * 1/2</li>
<li>Si A et B sont indépendants, alors P(A|B) = P(A) et P(B|A) = P(B)</li>
</ul>
</li>
</ul>
<h3 id="loi-des-grands-nombres">Loi des grands Nombres</h3>
<ul>
<li>La loi des grands nombres stipule que la fréquence relative d&rsquo;un événement converge vers sa probabilité théorique à mesure que le nombre d&rsquo;essais augmente
<ul>
<li>Exemple : lancer une pièce 1000 fois, la fréquence de face devrait être proche de 0.5</li>
</ul>
</li>
</ul>
<h4 id="espérance-mathématique">Espérance Mathématique</h4>
<ul>
<li>Espérance (E(X)) : moyenne pondérée des valeurs possibles d&rsquo;une variable aléatoire X
<ul>
<li>Exemple : lancer un dé, X = valeur obtenue, E(X) = (1+2+3+4+5+6)/6 = 3.5</li>
<li>Formule : E(X) = Σ [xi * P(X=xi)] pour toutes les valeurs xi de X</li>
<li>Propriétés : E(aX + b) = aE(X) + b, pour toute constante a et b</li>
</ul>
</li>
</ul>
<h4 id="variance-et-ecart-type">Variance et Ecart-type</h4>
<ul>
<li>Variance (Var(X)) : mesure de la dispersion des valeurs autour de l&rsquo;espérance
<ul>
<li>Exemple : lancer un dé, X = valeur obtenue, Var(X) = E(X²) - [E(X)]² = (1²+2²+3²+4²+5²+6²)/6 - (3.5)² = 2.9167</li>
<li>Formule : Var(X) = E[(X - E(X))²] = Σ [(xi - E(X))² * P(X=xi)]</li>
</ul>
</li>
</ul>
<h3 id="interprétation-graphique-et-intuition-ia">Interprétation graphique et Intuition IA</h3>
<p>Les probabilités sont fondamentales en IA pour modéliser l&rsquo;incertitude et prendre des décisions basées sur des données incomplètes ou bruitées. Elles permettent de :</p>
<ul>
<li>Modéliser des distributions de données (ex : Naive Bayes, modèles génératifs)</li>
<li>Estimer des paramètres (ex : Maximum de vraisemblance)</li>
<li>Faire des inférences (ex : réseaux bayésiens)</li>
<li>Gérer l&rsquo;incertitude (ex : filtres de Kalman, processus de Markov)</li>
<li>Évaluer des modèles (ex : validation croisée, métriques probabilistes)</li>
<li>Optimiser des fonctions (ex : algorithmes de Monte Carlo, optimisation bayésienne)</li>
</ul>
<h4 id="loi-uniforme-discrète">Loi uniforme discrète</h4>
<ul>
<li>La loi uniforme discrète modélise une situation où chaque résultat d&rsquo;un ensemble fini a la même probabilité de se produire.
<ul>
<li>Exemple : lancer un dé équilibré, chaque face (1 à 6) a une probabilité égale de 1/6.</li>
<li>Propriétés :
<ul>
<li>Nombre de résultats possibles : n</li>
<li>Probabilité de chaque résultat : P(X=xi) = 1/n pour i = 1, 2, &hellip;, n</li>
<li>Espérance : E(X) = (n + 1) / 2</li>
<li>Variance : Var(X) = (n² - 1) / 12</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="loi-binomiale">Loi binomiale</h4>
<ul>
<li>La loi binomiale modélise le nombre de succès dans une séquence de n essais indépendants, chacun ayant une probabilité p de succès.
<ul>
<li>Exemple : lancer une pièce 10 fois, X = nombre de faces obtenues, X suit une loi binomiale B(n=10, p=0.5).</li>
<li>Propriétés :
<ul>
<li>Nombre d&rsquo;essais : n</li>
<li>Probabilité de succès : p</li>
<li>Probabilité d&rsquo;échec : q = 1 - p</li>
<li>Fonction de probabilité : P(X=k) = C(n,k) * p^k * q^(n-k) pour k = 0, 1, &hellip;, n</li>
<li>Espérance : E(X) = n * p</li>
<li>Variance : Var(X) = n * p * q</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>Loi géométrique</p>
<ul>
<li>La loi géométrique modélise le nombre d&rsquo;essais nécessaires pour obtenir le premier succès dans une séquence d&rsquo;essais indépendants, chacun ayant une probabilité p de succès.
<ul>
<li>Exemple : lancer une pièce jusqu&rsquo;à obtenir face, X = nombre de lancers nécessaires, X suit une loi géométrique G(p=0.5).</li>
<li>Propriétés :
<ul>
<li>Probabilité de succès : p</li>
<li>Probabilité d&rsquo;échec : q = 1 - p</li>
<li>Fonction de probabilité : P(X=k) = q^(k-1) * p pour k = 1, 2, &hellip;</li>
<li>Espérance : E(X) = 1 / p</li>
<li>Variance : Var(X) = q / p²</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>Loi de poisson</p>
<ul>
<li>La loi de Poisson modélise le nombre d&rsquo;événements se produisant dans un intervalle de temps ou d&rsquo;espace donné, lorsque ces événements se produisent avec une moyenne constante et indépendamment du temps écoulé depuis le dernier événement.
<ul>
<li>Exemple : nombre d&rsquo;appels reçus par un centre d&rsquo;appel en une heure, X suit une loi de Poisson P(λ=5) si en moyenne 5 appels sont reçus par heure.</li>
<li>Propriétés :
<ul>
<li>Paramètre : λ (taux moyen d&rsquo;événements par intervalle)</li>
<li>Fonction de probabilité : P(X=k) = (e^(-λ) * λ^k) / k! pour k = 0, 1, 2, &hellip;</li>
<li>Espérance : E(X) = λ</li>
<li>Variance : Var(X) = λ</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>Lois continues</p>
<ul>
<li>Les lois continues modélisent des variables aléatoires pouvant prendre une infinité de valeurs dans un intervalle donné.
<ul>
<li>Exemple : taille, poids, temps d&rsquo;attente</li>
<li>Fonction de densité de probabilité (f(x)) : décrit la probabilité relative d&rsquo;une variable aléatoire continue prenant une valeur spécifique</li>
<li>Probabilité d&rsquo;un intervalle : P(a ≤ X ≤ b) = ∫[a à b] f(x) dx</li>
<li>Espérance : E(X) = ∫[−∞ à +∞] x * f(x) dx</li>
<li>Variance : Var(X) = ∫[−∞ à +∞] (x - E(X))² * f(x) dx</li>
</ul>
</li>
</ul>
<p>Loi uniforme continue</p>
<ul>
<li>La loi uniforme continue modélise une situation où chaque valeur dans un intervalle [a, b] a la même probabilité de se produire.
<ul>
<li>Exemple : choisir un nombre aléatoire entre 0 et 1, X suit une loi uniforme continue U(a=0, b=1).</li>
<li>Propriétés :
<ul>
<li>Intervalle : [a, b]</li>
<li>Fonction de densité : f(x) = 1/(b-a) pour x dans [a, b], f(x) = 0 ailleurs</li>
<li>Espérance : E(X) = (a + b) / 2</li>
<li>Variance : Var(X) = (b - a)² / 12</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>Choisir la bonne loi:</p>
<ul>
<li>Comprendre la nature des données (discrètes vs continues)</li>
<li>Analyser les caractéristiques des données (moyenne, variance, forme de la distribution)</li>
<li>Utiliser des tests statistiques (ex : test de Kolmogorov-Smirnov, test de Chi-carré)</li>
<li>Visualiser les données (histogrammes, Q-Q plots)</li>
<li>Consulter des ressources et des experts en statistique si nécessaire</li>
<li>Exemples d&rsquo;application en IA:</li>
<li>Classification : Naive Bayes utilise des probabilités conditionnelles pour classer les données</li>
<li>Réseaux bayésiens : modélisent les relations de dépendance entre variables</li>
<li>Apprentissage par renforcement : utilise des probabilités pour modéliser les récompenses et les transitions d&rsquo;état</li>
<li>Traitement du langage naturel : modèles de langage probabilistes (ex : n-grammes)</li>
<li>Vision par ordinateur : modèles génératifs pour la synthèse d&rsquo;images (ex : GANs)</li>
<li>Modèles de Markov cachés : utilisés pour la reconnaissance vocale et la bioinformatique</li>
<li>Algorithmes de Monte Carlo : utilisés pour l&rsquo;optimisation et la simulation</li>
<li>Optimisation bayésienne : utilisée pour l&rsquo;optimisation de fonctions coûteuses à évaluer</li>
<li>Ressources supplémentaires:
Livres : &ldquo;Probabilités pour les sciences de l&rsquo;ingénieur&rdquo; de Sheldon Ross, &ldquo;Pattern Recognition and Machine Learning&rdquo; de Christopher Bishop</li>
</ul>

                </article>
            </div>
        </div>
    </div>
</div>

    </main>

    
    <footer>
        <div class="container">
            <div class="row">
                <div class="col-md-6">
                    <h5><i class="fas fa-user-circle"></i> Ismael Martinez</h5>
                    <p>Portfolio professionnel et documentation technique d&#39;Ismael Martinez</p>
                </div>
                <div class="col-md-6 text-md-end">
                    <p><i class="fas fa-rocket"></i> Généré avec Hugo</p>
                    <p>&copy; 2025 Ismael Martinez</p>
                </div>
            </div>
        </div>
    </footer>

    
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
</body>
</html>